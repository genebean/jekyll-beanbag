<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.16.2 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Elk Stack Design - The Comfy Seat</title>
<meta name="description" content="I’ve been working on a new logging system based around Elasticsearch, Logstash, and Kibana. One of my biggest challenges was that all the recommended designs I found said that logs should go from a shipper to Redis. The problems with this are twofold:	Logstash doesn&#39;t seem like a good fit for Windows. The biggest issues are that it relies on Java which isn&#39;t something that is very sellable to any Windows admin that I know. The other is that it simply didn&#39;t work reliably in my testing. The 1.4.x series had performance issues and the copy of 1.5.1 I just tried on Windows 7 is throwingWindows Event Log error: Invoke of: NextEventSource: SWbemEventSourceDescription: Timed outerrors under even the simplest of tests. Unlike other tools it also requires specifying each Event Log that you want to monitor individually as opposed to being able to just grab them all.	Not everything can have an agent on it which means that I needed a way to pipe syslog into RedisThe Windows issues were solved by utilizing NXLog as a log shipper but that introduced another problem: NXLog doesn’t have a Redis output. On the plus side though, NXLog seems to be the gold standard when it comes to getting at Event Log data and it can convert the log entries into JSON. This just leaves finding a way to add the Logstash-specific information to the message and then a way to insert that message into Redis. As it turns out, this issue is not that different from the one of piping syslog into Redis. After looking around for several days I found that there weren’t really any good solutions to this other than standing up a separate Logstash server. This seemed like a huge waste of resources and also proved to be problematic when trying to start out with all services on a single node. These needs precipitated me writing Sawyer. Sawyer is a Node.js application that accepts these inputs, massages them accordingly, and then inserts them into Redis for Logstash to pick up.Infrastructure: Take 1With Sawyer getting syslog data and JSON from NXLog (or other sources) into Redis I could now focus on really building out my infrastructure. As eluded to earlier, I started out with everything on one box. This included all of the ELK stack, two Redis instances, Sawyer, and Apache. Apache was setup to protect all of this by way of Apache’s mod_authnz_ldap and basic auth. This allowed some rudimentary access control via HTTP Basic Auth backed by Active Directory. Shipping our ISC DHCP logs, firewall logs, all logs from our domain controllers, all logs from our Windows RADIUS servers (NPS Servers), and the Apache logs from the software repository we run quickly caused this setup to fall over.Infrastructure: Take 2Since one node wasn’t cutting it I decided it was time to scale the entire system out based on some recommendations from some very helpful people at Elastic. Below is a diagram of the setup I am currently implementing:[caption id=”attachment_144” align=”aligncenter” width=”2550”] Click for a much larger version.[/caption]This design accomplishes a few different things:	more processing capacity for both Logstash and Elasticsearch	redundancy in data storage	redundant and load balanced Redis nodes	dedicated Elasticsearch mastersEach log source in this setup, be it a server with an agent of some kind or a device shipping raw syslog data, is configured to point at a single virtual IP. That VIP resolves to a HA pair of F5 load balancers that route the traffic to a pair of nodes running Redis and Sawyer. A pair of Logstash servers each pull from both Redis nodes, index the data, and output it to an Elasticsearch cluster. Kibana is setup on the same host as an Elasticsearch query node which allows it to pull data from the entire cluster instead of just one of the data nodes.Licensing and Additional FeaturesElastic’s Gold Subscription provides support plus access to some additional products including Shield, Marvel, and Watcher. The subscription is per data node so this setup helps keep the costs down while still providing the recommended resiliency for the masters. Shield gives you the ability to implement full RBAC for you logs, Marvel helps you keep and eye on your cluster, and Watcher allows you to do alerting based on information in your logs. When you combine these features with the comfort of having support it seems like a no-brainer to me.A note on log shippersFinding shippers has been the single biggest challenge of this setup. My requirements aren’t that lofty:	It should be installable via a package manager. On Windows this means it needs to be available via Chocolatey. On Linux I prefer it when the vendor provides repositories for Red Hat and Ubuntu based systems.	It should be fairly light on resources so that it can be integrated into existing systems without a change in resources (particularly RAM).	It needs to be able to be managed by Puppet	It needs to output to Redis or at least output JSON	It needs to support a variety of inputs including flat filesHere are some of the pros and cons I found while researching the available options:	Logstash itself is disappointing here... it requires Java which isn&#39;t exactly light on resources. On the receiver-side I do prefer this but may want or need to avoid it on the shipping side.	Logstash Forwarder is light but only ships via the Lumberjack protocol. To get this into a broker such as Redis I would have to first route it through a Logstash instance. On the up side it does support encryption so it may be of use for certain hosts.	Beaver, a python application, doesn&#39;t support Windows Event Log and doesn&#39;t really offer anything to tempt me away from other options.	Woodchuck is written in Ruby which is also a dependency of Puppet so is already installed on all nodes. On the downside, it doesn&#39;t support Windows Event Log nor does it support tagging.	Fluentd is actually quite nice and looks more and more like what I will end up using as my shipper on non-Windows servers. It can also be used instead of Logstash on the receiving side. I tried an Elasticsearch, Fluentd, and Kibana stack and just didn&#39;t like the format of the data nearly as much. Fluentd also offers integration with programming languages including:	PHP	Ruby	Node.js	JavaThis allows for logging directly from applications instead of to a flat file that then must be read and parsed.ConclusionAll in all I have been absolutely amazed at how easy everything has been to setup. I am quite impressed with everything thus far and am looking forward to finishing my scale out so that I can start shipping logs from many more sources. I plan to start bringing in logs from all servers and their applications, from switches and access points, and everywhere else I can think of.">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="The Comfy Seat">
<meta property="og:title" content="Elk Stack Design">
<meta property="og:url" content="http://localhost:4000/jekyll-beanbag/http:/beanbag.technicalissues.us/2015/06/elk-stack-design/">


  <meta property="og:description" content="I’ve been working on a new logging system based around Elasticsearch, Logstash, and Kibana. One of my biggest challenges was that all the recommended designs I found said that logs should go from a shipper to Redis. The problems with this are twofold:	Logstash doesn&#39;t seem like a good fit for Windows. The biggest issues are that it relies on Java which isn&#39;t something that is very sellable to any Windows admin that I know. The other is that it simply didn&#39;t work reliably in my testing. The 1.4.x series had performance issues and the copy of 1.5.1 I just tried on Windows 7 is throwingWindows Event Log error: Invoke of: NextEventSource: SWbemEventSourceDescription: Timed outerrors under even the simplest of tests. Unlike other tools it also requires specifying each Event Log that you want to monitor individually as opposed to being able to just grab them all.	Not everything can have an agent on it which means that I needed a way to pipe syslog into RedisThe Windows issues were solved by utilizing NXLog as a log shipper but that introduced another problem: NXLog doesn’t have a Redis output. On the plus side though, NXLog seems to be the gold standard when it comes to getting at Event Log data and it can convert the log entries into JSON. This just leaves finding a way to add the Logstash-specific information to the message and then a way to insert that message into Redis. As it turns out, this issue is not that different from the one of piping syslog into Redis. After looking around for several days I found that there weren’t really any good solutions to this other than standing up a separate Logstash server. This seemed like a huge waste of resources and also proved to be problematic when trying to start out with all services on a single node. These needs precipitated me writing Sawyer. Sawyer is a Node.js application that accepts these inputs, massages them accordingly, and then inserts them into Redis for Logstash to pick up.Infrastructure: Take 1With Sawyer getting syslog data and JSON from NXLog (or other sources) into Redis I could now focus on really building out my infrastructure. As eluded to earlier, I started out with everything on one box. This included all of the ELK stack, two Redis instances, Sawyer, and Apache. Apache was setup to protect all of this by way of Apache’s mod_authnz_ldap and basic auth. This allowed some rudimentary access control via HTTP Basic Auth backed by Active Directory. Shipping our ISC DHCP logs, firewall logs, all logs from our domain controllers, all logs from our Windows RADIUS servers (NPS Servers), and the Apache logs from the software repository we run quickly caused this setup to fall over.Infrastructure: Take 2Since one node wasn’t cutting it I decided it was time to scale the entire system out based on some recommendations from some very helpful people at Elastic. Below is a diagram of the setup I am currently implementing:[caption id=”attachment_144” align=”aligncenter” width=”2550”] Click for a much larger version.[/caption]This design accomplishes a few different things:	more processing capacity for both Logstash and Elasticsearch	redundancy in data storage	redundant and load balanced Redis nodes	dedicated Elasticsearch mastersEach log source in this setup, be it a server with an agent of some kind or a device shipping raw syslog data, is configured to point at a single virtual IP. That VIP resolves to a HA pair of F5 load balancers that route the traffic to a pair of nodes running Redis and Sawyer. A pair of Logstash servers each pull from both Redis nodes, index the data, and output it to an Elasticsearch cluster. Kibana is setup on the same host as an Elasticsearch query node which allows it to pull data from the entire cluster instead of just one of the data nodes.Licensing and Additional FeaturesElastic’s Gold Subscription provides support plus access to some additional products including Shield, Marvel, and Watcher. The subscription is per data node so this setup helps keep the costs down while still providing the recommended resiliency for the masters. Shield gives you the ability to implement full RBAC for you logs, Marvel helps you keep and eye on your cluster, and Watcher allows you to do alerting based on information in your logs. When you combine these features with the comfort of having support it seems like a no-brainer to me.A note on log shippersFinding shippers has been the single biggest challenge of this setup. My requirements aren’t that lofty:	It should be installable via a package manager. On Windows this means it needs to be available via Chocolatey. On Linux I prefer it when the vendor provides repositories for Red Hat and Ubuntu based systems.	It should be fairly light on resources so that it can be integrated into existing systems without a change in resources (particularly RAM).	It needs to be able to be managed by Puppet	It needs to output to Redis or at least output JSON	It needs to support a variety of inputs including flat filesHere are some of the pros and cons I found while researching the available options:	Logstash itself is disappointing here... it requires Java which isn&#39;t exactly light on resources. On the receiver-side I do prefer this but may want or need to avoid it on the shipping side.	Logstash Forwarder is light but only ships via the Lumberjack protocol. To get this into a broker such as Redis I would have to first route it through a Logstash instance. On the up side it does support encryption so it may be of use for certain hosts.	Beaver, a python application, doesn&#39;t support Windows Event Log and doesn&#39;t really offer anything to tempt me away from other options.	Woodchuck is written in Ruby which is also a dependency of Puppet so is already installed on all nodes. On the downside, it doesn&#39;t support Windows Event Log nor does it support tagging.	Fluentd is actually quite nice and looks more and more like what I will end up using as my shipper on non-Windows servers. It can also be used instead of Logstash on the receiving side. I tried an Elasticsearch, Fluentd, and Kibana stack and just didn&#39;t like the format of the data nearly as much. Fluentd also offers integration with programming languages including:	PHP	Ruby	Node.js	JavaThis allows for logging directly from applications instead of to a flat file that then must be read and parsed.ConclusionAll in all I have been absolutely amazed at how easy everything has been to setup. I am quite impressed with everything thus far and am looking forward to finishing my scale out so that I can start shipping logs from many more sources. I plan to start bringing in logs from all servers and their applications, from switches and access points, and everywhere else I can think of.">







  <meta property="article:published_time" content="2015-06-19T00:00:00-04:00">






<link rel="canonical" href="http://localhost:4000/jekyll-beanbag/http:/beanbag.technicalissues.us/2015/06/elk-stack-design/">













<!-- end _includes/seo.html -->


<link href="/jekyll-beanbag/feed.xml" type="application/atom+xml" rel="alternate" title="The Comfy Seat Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/jekyll-beanbag/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/jekyll-beanbag/"><img src="/jekyll-beanbag/assets/images/the-comfy-seat.png" alt=""></a>
        
        <a class="site-title" href="/jekyll-beanbag/">The Comfy Seat</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/jekyll-beanbag/posts/" >Posts</a>
            </li><li class="masthead__menu-item">
              <a href="/jekyll-beanbag/categories/" >Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/jekyll-beanbag/tags/" >Tags</a>
            </li><li class="masthead__menu-item">
              <a href="/jekyll-beanbag/about/" >About</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Elk Stack Design">
    <meta itemprop="description" content="I’ve been working on a new logging system based around Elasticsearch, Logstash, and Kibana. One of my biggest challenges was that all the recommended designs I found said that logs should go from a shipper to Redis. The problems with this are twofold:	Logstash doesn&#39;t seem like a good fit for Windows. The biggest issues are that it relies on Java which isn&#39;t something that is very sellable to any Windows admin that I know. The other is that it simply didn&#39;t work reliably in my testing. The 1.4.x series had performance issues and the copy of 1.5.1 I just tried on Windows 7 is throwingWindows Event Log error: Invoke of: NextEventSource: SWbemEventSourceDescription: Timed outerrors under even the simplest of tests. Unlike other tools it also requires specifying each Event Log that you want to monitor individually as opposed to being able to just grab them all.	Not everything can have an agent on it which means that I needed a way to pipe syslog into RedisThe Windows issues were solved by utilizing NXLog as a log shipper but that introduced another problem: NXLog doesn’t have a Redis output. On the plus side though, NXLog seems to be the gold standard when it comes to getting at Event Log data and it can convert the log entries into JSON. This just leaves finding a way to add the Logstash-specific information to the message and then a way to insert that message into Redis. As it turns out, this issue is not that different from the one of piping syslog into Redis. After looking around for several days I found that there weren’t really any good solutions to this other than standing up a separate Logstash server. This seemed like a huge waste of resources and also proved to be problematic when trying to start out with all services on a single node. These needs precipitated me writing Sawyer. Sawyer is a Node.js application that accepts these inputs, massages them accordingly, and then inserts them into Redis for Logstash to pick up.Infrastructure: Take 1With Sawyer getting syslog data and JSON from NXLog (or other sources) into Redis I could now focus on really building out my infrastructure. As eluded to earlier, I started out with everything on one box. This included all of the ELK stack, two Redis instances, Sawyer, and Apache. Apache was setup to protect all of this by way of Apache’s mod_authnz_ldap and basic auth. This allowed some rudimentary access control via HTTP Basic Auth backed by Active Directory. Shipping our ISC DHCP logs, firewall logs, all logs from our domain controllers, all logs from our Windows RADIUS servers (NPS Servers), and the Apache logs from the software repository we run quickly caused this setup to fall over.Infrastructure: Take 2Since one node wasn’t cutting it I decided it was time to scale the entire system out based on some recommendations from some very helpful people at Elastic. Below is a diagram of the setup I am currently implementing:[caption id=”attachment_144” align=”aligncenter” width=”2550”] Click for a much larger version.[/caption]This design accomplishes a few different things:	more processing capacity for both Logstash and Elasticsearch	redundancy in data storage	redundant and load balanced Redis nodes	dedicated Elasticsearch mastersEach log source in this setup, be it a server with an agent of some kind or a device shipping raw syslog data, is configured to point at a single virtual IP. That VIP resolves to a HA pair of F5 load balancers that route the traffic to a pair of nodes running Redis and Sawyer. A pair of Logstash servers each pull from both Redis nodes, index the data, and output it to an Elasticsearch cluster. Kibana is setup on the same host as an Elasticsearch query node which allows it to pull data from the entire cluster instead of just one of the data nodes.Licensing and Additional FeaturesElastic’s Gold Subscription provides support plus access to some additional products including Shield, Marvel, and Watcher. The subscription is per data node so this setup helps keep the costs down while still providing the recommended resiliency for the masters. Shield gives you the ability to implement full RBAC for you logs, Marvel helps you keep and eye on your cluster, and Watcher allows you to do alerting based on information in your logs. When you combine these features with the comfort of having support it seems like a no-brainer to me.A note on log shippersFinding shippers has been the single biggest challenge of this setup. My requirements aren’t that lofty:	It should be installable via a package manager. On Windows this means it needs to be available via Chocolatey. On Linux I prefer it when the vendor provides repositories for Red Hat and Ubuntu based systems.	It should be fairly light on resources so that it can be integrated into existing systems without a change in resources (particularly RAM).	It needs to be able to be managed by Puppet	It needs to output to Redis or at least output JSON	It needs to support a variety of inputs including flat filesHere are some of the pros and cons I found while researching the available options:	Logstash itself is disappointing here... it requires Java which isn&#39;t exactly light on resources. On the receiver-side I do prefer this but may want or need to avoid it on the shipping side.	Logstash Forwarder is light but only ships via the Lumberjack protocol. To get this into a broker such as Redis I would have to first route it through a Logstash instance. On the up side it does support encryption so it may be of use for certain hosts.	Beaver, a python application, doesn&#39;t support Windows Event Log and doesn&#39;t really offer anything to tempt me away from other options.	Woodchuck is written in Ruby which is also a dependency of Puppet so is already installed on all nodes. On the downside, it doesn&#39;t support Windows Event Log nor does it support tagging.	Fluentd is actually quite nice and looks more and more like what I will end up using as my shipper on non-Windows servers. It can also be used instead of Logstash on the receiving side. I tried an Elasticsearch, Fluentd, and Kibana stack and just didn&#39;t like the format of the data nearly as much. Fluentd also offers integration with programming languages including:	PHP	Ruby	Node.js	JavaThis allows for logging directly from applications instead of to a flat file that then must be read and parsed.ConclusionAll in all I have been absolutely amazed at how easy everything has been to setup. I am quite impressed with everything thus far and am looking forward to finishing my scale out so that I can start shipping logs from many more sources. I plan to start bringing in logs from all servers and their applications, from switches and access points, and everywhere else I can think of.">
    <meta itemprop="datePublished" content="June 19, 2015">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Elk Stack Design
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  5 minute read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>I’ve been working on a new logging system based around <a href="https://www.elastic.co/products/elasticsearch" target="_blank">Elasticsearch</a>, <a href="https://www.elastic.co/products/logstash" target="_blank">Logstash</a>, and <a href="https://www.elastic.co/products/kibana" target="_blank">Kibana</a>. One of my biggest challenges was that all the recommended designs I found said that logs should go from a shipper to <a href="http://redis.io" target="_blank">Redis</a>. The problems with this are twofold:</p>
<ol>
	<li>Logstash doesn't seem like a good fit for Windows. The biggest issues are that it relies on Java which isn't something that is very sellable to any Windows admin that I know. The other is that it simply didn't work reliably in my testing. The <a title="Logstash 1.5.0 GA release notes" href="https://www.elastic.co/blog/logstash-1-5-0-ga-released" target="_blank">1.4.x series had performance issues</a> and the copy of 1.5.1 I just tried on Windows 7 is throwing
<code>Windows Event Log error: Invoke of: NextEvent
Source: SWbemEventSource
Description: Timed out</code>
errors under even the simplest of tests. Unlike other tools it also requires specifying each Event Log that you want to monitor individually as opposed to being able to just grab them all.</li>
	<li>Not everything can have an agent on it which means that I needed a way to pipe syslog into Redis</li>
</ol>
<p>The Windows issues were solved by utilizing <a title="NXLog Community Edition" href="http://nxlog.org/products/nxlog-community-edition" target="_blank">NXLog</a> as a log shipper but that introduced another problem: NXLog doesn’t have a Redis output. On the plus side though, NXLog seems to be the gold standard when it comes to getting at Event Log data and it can <a href="http://nxlog.org/docs/nxlog-ce/nxlog-reference-manual.html#xm_json" target="_blank">convert the log entries into JSON</a>. This just leaves finding a way to add the Logstash-specific information to the message and then a way to insert that message into Redis.<!--more--> As it turns out, this issue is not that different from the one of piping syslog into Redis. After looking around for several days I found that there weren’t really any good solutions to this other than standing up a separate Logstash server. This seemed like a huge waste of resources and also proved to be problematic when trying to start out with all services on a single node. These needs precipitated me writing <a title="Sawyer on GitHub" href="https://github.com/genebean/sawyer" target="_blank">Sawyer</a>. Sawyer is a <a href="https://nodejs.org/" target="_blank">Node.js</a> application that accepts these inputs, massages them accordingly, and then inserts them into Redis for Logstash to pick up.</p>
<h1>Infrastructure: Take 1</h1>
<p>With Sawyer getting syslog data and JSON from NXLog (or other sources) into Redis I could now focus on really building out my infrastructure. As eluded to earlier, I started out with everything on one box. This included all of the ELK stack, two Redis instances, Sawyer, and Apache. Apache was setup to protect all of this by way of Apache’s <a title="Apache mod_authnz_ldap docs" href="http://httpd.apache.org/docs/2.2/mod/mod_authnz_ldap.html" target="_blank">mod_authnz_ldap</a> and basic auth. This allowed some rudimentary access control via HTTP Basic Auth backed by Active Directory. Shipping our <a title="ISC DHCP" href="https://www.isc.org/downloads/dhcp/" target="_blank">ISC DHCP</a> logs, firewall logs, all logs from our domain controllers, all logs from our Windows RADIUS servers (NPS Servers), and the Apache logs from <a title="Reflector: UWG's Software Mirror" href="http://reflector.westga.edu" target="_blank">the software repository we run</a> quickly caused this setup to fall over.</p>
<h1>Infrastructure: Take 2</h1>
<p>Since one node wasn’t cutting it I decided it was time to scale the entire system out based on some recommendations from some very helpful people at <a title="Elastic website" href="https://www.elastic.co" target="_blank">Elastic</a>. Below is a diagram of the setup I am currently implementing:</p>

<p>[caption id=”attachment_144” align=”aligncenter” width=”2550”]<a href="http://res.cloudinary.com/genebean/image/upload/v1438140565/ELK-Stack_s3pc7v.png"><img class="wp-image-144 size-full" src="http://res.cloudinary.com/genebean/image/upload/v1438140565/ELK-Stack_s3pc7v.png" alt="Infrastructure Diagram" width="2550" height="5417" /></a> Click for a much larger version.[/caption]</p>

<p>This design accomplishes a few different things:</p>
<ul>
	<li>more processing capacity for both Logstash and Elasticsearch</li>
	<li>redundancy in data storage</li>
	<li>redundant and load balanced Redis nodes</li>
	<li>dedicated Elasticsearch masters</li>
</ul>
<p>Each log source in this setup, be it a server with an agent of some kind or a device shipping raw syslog data, is configured to point at a single virtual IP. That VIP resolves to a HA pair of F5 load balancers that route the traffic to a pair of nodes running Redis and Sawyer. A pair of Logstash servers each pull from both Redis nodes, index the data, and output it to an Elasticsearch cluster. Kibana is setup on the same host as an Elasticsearch query node which allows it to pull data from the entire cluster instead of just one of the data nodes.</p>
<h2>Licensing and Additional Features</h2>
<p><a title="Elastic subsciptions" href="https://www.elastic.co/subscriptions" target="_blank">Elastic’s Gold Subscription</a> provides support plus access to some additional products including Shield, Marvel, and Watcher. The subscription is per data node so this setup helps keep the costs down while still providing the recommended resiliency for the masters. Shield gives you the ability to implement full RBAC for you logs, Marvel helps you keep and eye on your cluster, and Watcher allows you to do alerting based on information in your logs. When you combine these features with the comfort of having support it seems like a no-brainer to me.</p>
<h1>A note on log shippers</h1>
<p>Finding shippers has been the single biggest challenge of this setup. My requirements aren’t that lofty:</p>
<ul>
	<li>It should be installable via a package manager. On Windows this means it needs to be available via <a title="Chocolatey" href="https://chocolatey.org" target="_blank">Chocolatey</a>. On Linux I prefer it when the vendor provides repositories for Red Hat and Ubuntu based systems.</li>
	<li>It should be fairly light on resources so that it can be integrated into existing systems without a change in resources (particularly RAM).</li>
	<li>It needs to be able to be managed by Puppet</li>
	<li>It needs to output to Redis or at least output JSON</li>
	<li>It needs to support a variety of inputs including flat files</li>
</ul>
<p>Here are some of the pros and cons I found while researching the available options:</p>
<ul>
	<li><a title="Logstash product page" href="https://www.elastic.co/products/logstash" target="_blank">Logstash</a> itself is disappointing here... it requires Java which isn't exactly light on resources. On the receiver-side I do prefer this but may want or need to avoid it on the shipping side.</li>
	<li><a title="Logstash Forwarder at GitHub" href="https://github.com/elastic/logstash-forwarder" target="_blank">Logstash Forwarder</a> is light but only ships via the Lumberjack protocol. To get this into a broker such as Redis I would have to first route it through a Logstash instance. On the up side it does support encryption so it may be of use for certain hosts.</li>
	<li><a title="Beaver at GitHub" href="https://github.com/josegonzalez/python-beaver" target="_blank">Beaver</a>, a python application, doesn't support Windows Event Log and doesn't really offer anything to tempt me away from other options.</li>
	<li><a title="Woodchuck on GitHub" href="https://github.com/danryan/woodchuck" target="_blank">Woodchuck</a> is written in Ruby which is also a dependency of Puppet so is already installed on all nodes. On the downside, it doesn't support Windows Event Log nor does it support tagging.</li>
	<li><a title="Fluentd website" href="http://www.fluentd.org" target="_blank">Fluentd</a> is actually quite nice and looks more and more like what I will end up using as my shipper on non-Windows servers. It can also be used instead of Logstash on the receiving side. I tried an Elasticsearch, Fluentd, and Kibana stack and just didn't like the format of the data nearly as much. Fluentd also offers integration with programming languages including:
<ul>
	<li><a title="Fluentd and PHP" href="http://docs.fluentd.org/articles/php" target="_blank">PHP</a></li>
	<li><a title="Fluentd and Ruby" href="http://docs.fluentd.org/articles/ruby" target="_blank">Ruby</a></li>
	<li><a title="Fluentd and Node.js" href="http://docs.fluentd.org/articles/nodejs" target="_blank">Node.js</a></li>
	<li><a title="Fluentd and Java" href="http://docs.fluentd.org/articles/java" target="_blank">Java</a></li>
</ul>
This allows for logging directly from applications instead of to a flat file that then must be read and parsed.</li>
</ul>
<h1>Conclusion</h1>
<p>All in all I have been absolutely amazed at how easy everything has been to setup. I am quite impressed with everything thus far and am looking forward to finishing my scale out so that I can start shipping logs from many more sources. I plan to start bringing in logs from all servers and their applications, from switches and access points, and everywhere else I can think of.</p>

        
      </section>

      <footer class="page__meta">
        
        


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2015-06-19T00:00:00-04:00">June 19, 2015</time></p>
        
      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Elk+Stack+Design%20http%3A%2F%2Flocalhost%3A4000%2Fjekyll-beanbag%2Fhttp%3A%2Fbeanbag.technicalissues.us%2F2015%2F06%2Felk-stack-design%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fjekyll-beanbag%2Fhttp%3A%2Fbeanbag.technicalissues.us%2F2015%2F06%2Felk-stack-design%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fjekyll-beanbag%2Fhttp%3A%2Fbeanbag.technicalissues.us%2F2015%2F06%2Felk-stack-design%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/jekyll-beanbag/windows-7-x64-underscore-cli/" class="pagination--pager" title="Windows 7 x64 and Underscore-CLI
">Previous</a>
    
    
      <a href="/jekyll-beanbag/elk-stack-design/" class="pagination--pager" title="ELK Stack Design
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/jekyll-beanbag/breaking-up-a-large-pull-request/" rel="permalink">Breaking up a large pull request
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  3 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Ever finished up all the changes for a pull request on GitHub and realized it was just too big to review easily or to reason about what’s going on? I had jus...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/jekyll-beanbag/protecting-sensitive-data-in-puppet-code/" rel="permalink">My journey to securing sensitive data in Puppet code
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  13 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Dealing with secrets and sensitive data in Puppet is daunting, right? Nope, not at all. Let me show you how to do it. I’ve wrapped my head around the options...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/jekyll-beanbag/dual-booting-macos-high-sierra-and-linux-mint/" rel="permalink">Dual Booting macOS High Sierra and Linux Mint
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  11 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">This is a step-by-step walkthrough for dual booting a MacBook Pro (Mid-2015 aka MacBookPro11,5) that already has macOS High Sierra on it with Linux Mint. The...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/jekyll-beanbag/gitlab-ci-and-chocolatey-server/" rel="permalink">GitLab CI and Chocolatey Server
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  5 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">If you are not familiar with chocolatey, its an awesome package manager, like apt or yum, for Windows. You can also host your own internal chocolatey feed an...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="search" id="search" aria-placeholder="Enter your search term..." class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>

      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://github.com/genebean" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://twitter.com/technicalissues" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://app.vagrantup.com/genebean" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-link" aria-hidden="true"></i> Vagrant Boxes</a></li>
        
      
    

    <li><a href="/jekyll-beanbag/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2019 The Comfy Seat. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/jekyll-beanbag/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.8.1/js/all.js" integrity="sha384-g5uSoOSBd7KkhAMlnQILrecXvzst9TdC09/VM+pjDTCM+1il8RHz5fKANTFFb+gQ" crossorigin="anonymous"></script>




<script src="/jekyll-beanbag/assets/js/lunr/lunr.min.js"></script>
<script src="/jekyll-beanbag/assets/js/lunr/lunr-store.js"></script>
<script src="/jekyll-beanbag/assets/js/lunr/lunr-en.js"></script>







  </body>
</html>
